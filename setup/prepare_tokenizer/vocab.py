# prepare_tokenizer/vocab.py

AA_VOCAB = [
    "<PAD>",
    "<MASK>",
    "<CLS>",
    "<SEP>",
    "<EOS>",
    "<UNK>",
    "A",
    "C",
    "D",
    "E",
    "F",
    "G",
    "H",
    "I",
    "K",
    "L",
    "M",
    "N",
    "P",
    "Q",
    "R",
    "S",
    "T",
    "V",
    "W",
    "Y",
    "X",
    "B",
    "Z",
]
